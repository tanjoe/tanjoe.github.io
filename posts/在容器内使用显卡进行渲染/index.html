<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>在容器内使用显卡进行渲染 | Qiao</title><meta name=keywords content="Docker,CUDA,OpenGL"><meta name=description content="由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词nvidia opengl docker搜索了一番，发现应该很好完成。
结合几篇文章的内容，以及nvidia/opengl的Dockerfile来看，核心是安装libglvnd0及一些依赖库、配置好glvnd的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装mesa-utils和glmark2后，用glxinfo和glmark2都显示vendor是：
OpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits) 即仍然在使用软渲染，但nvidia-smi在容器内工作又是正常的。
使用集显 在Host机器上测试glxinfo和glmark2，发现vendor居然也不是nvidia而是MESA Intel，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。
测试后，发现在docker run时附带--device=/dev/dri:/dev/dri参数即可。这样操作后，容器内glxinfo总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。
关于Linux DRI，可参考Linux graphic subsystem(2)_DRI介绍的说明
使用独显 话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明nvidia-smi工作正常，CUDA的代码也能运行。带此疑问，用why glxinfo not detect nvidia while nividia-smi works搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。
最后本机上打开nvidia-settings查看设置时，发现Profile里的3个选项：
Nvidia (Performance mode) Nvidia On-Demand Intel (Power saving mode) 第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：
Nvidia On - Demand : Ubuntu
there&rsquo;s a good write up here: https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html
on-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is &lsquo;bumblebee mode&rsquo;, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work."><meta name=author content="Qiao"><link rel=canonical href=https://tanjoe.github.io/posts/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93/><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tanjoe.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://tanjoe.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://tanjoe.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://tanjoe.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://tanjoe.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>const config={startOnLoad:!0,theme:"forest",themeVariables:{lineColor:"#fafafa"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(void 0,document.querySelectorAll(".language-mermaid"))}</script><meta property="og:title" content="在容器内使用显卡进行渲染"><meta property="og:description" content="由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词nvidia opengl docker搜索了一番，发现应该很好完成。
结合几篇文章的内容，以及nvidia/opengl的Dockerfile来看，核心是安装libglvnd0及一些依赖库、配置好glvnd的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装mesa-utils和glmark2后，用glxinfo和glmark2都显示vendor是：
OpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits) 即仍然在使用软渲染，但nvidia-smi在容器内工作又是正常的。
使用集显 在Host机器上测试glxinfo和glmark2，发现vendor居然也不是nvidia而是MESA Intel，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。
测试后，发现在docker run时附带--device=/dev/dri:/dev/dri参数即可。这样操作后，容器内glxinfo总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。
关于Linux DRI，可参考Linux graphic subsystem(2)_DRI介绍的说明
使用独显 话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明nvidia-smi工作正常，CUDA的代码也能运行。带此疑问，用why glxinfo not detect nvidia while nividia-smi works搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。
最后本机上打开nvidia-settings查看设置时，发现Profile里的3个选项：
Nvidia (Performance mode) Nvidia On-Demand Intel (Power saving mode) 第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：
Nvidia On - Demand : Ubuntu
there&rsquo;s a good write up here: https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html
on-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is &lsquo;bumblebee mode&rsquo;, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work."><meta property="og:type" content="article"><meta property="og:url" content="https://tanjoe.github.io/posts/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93/"><meta property="og:image" content="https://tanjoe.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-01T10:01:29+00:00"><meta property="article:modified_time" content="2023-01-01T10:01:29+00:00"><meta property="og:site_name" content="Qiao"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://tanjoe.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="在容器内使用显卡进行渲染"><meta name=twitter:description content="由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词nvidia opengl docker搜索了一番，发现应该很好完成。
结合几篇文章的内容，以及nvidia/opengl的Dockerfile来看，核心是安装libglvnd0及一些依赖库、配置好glvnd的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装mesa-utils和glmark2后，用glxinfo和glmark2都显示vendor是：
OpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits) 即仍然在使用软渲染，但nvidia-smi在容器内工作又是正常的。
使用集显 在Host机器上测试glxinfo和glmark2，发现vendor居然也不是nvidia而是MESA Intel，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。
测试后，发现在docker run时附带--device=/dev/dri:/dev/dri参数即可。这样操作后，容器内glxinfo总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。
关于Linux DRI，可参考Linux graphic subsystem(2)_DRI介绍的说明
使用独显 话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明nvidia-smi工作正常，CUDA的代码也能运行。带此疑问，用why glxinfo not detect nvidia while nividia-smi works搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。
最后本机上打开nvidia-settings查看设置时，发现Profile里的3个选项：
Nvidia (Performance mode) Nvidia On-Demand Intel (Power saving mode) 第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：
Nvidia On - Demand : Ubuntu
there&rsquo;s a good write up here: https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html
on-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is &lsquo;bumblebee mode&rsquo;, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tanjoe.github.io/posts/"},{"@type":"ListItem","position":2,"name":"在容器内使用显卡进行渲染","item":"https://tanjoe.github.io/posts/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"在容器内使用显卡进行渲染","name":"在容器内使用显卡进行渲染","description":"由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词nvidia opengl docker搜索了一番，发现应该很好完成。\n结合几篇文章的内容，以及nvidia/opengl的Dockerfile来看，核心是安装libglvnd0及一些依赖库、配置好glvnd的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装mesa-utils和glmark2后，用glxinfo和glmark2都显示vendor是：\nOpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits) 即仍然在使用软渲染，但nvidia-smi在容器内工作又是正常的。\n使用集显 在Host机器上测试glxinfo和glmark2，发现vendor居然也不是nvidia而是MESA Intel，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。\n测试后，发现在docker run时附带--device=/dev/dri:/dev/dri参数即可。这样操作后，容器内glxinfo总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。\n关于Linux DRI，可参考Linux graphic subsystem(2)_DRI介绍的说明\n使用独显 话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明nvidia-smi工作正常，CUDA的代码也能运行。带此疑问，用why glxinfo not detect nvidia while nividia-smi works搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。\n最后本机上打开nvidia-settings查看设置时，发现Profile里的3个选项：\nNvidia (Performance mode) Nvidia On-Demand Intel (Power saving mode) 第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：\nNvidia On - Demand : Ubuntu\nthere\u0026rsquo;s a good write up here: https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html\non-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is \u0026lsquo;bumblebee mode\u0026rsquo;, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work.","keywords":["Docker","CUDA","OpenGL"],"articleBody":"由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词nvidia opengl docker搜索了一番，发现应该很好完成。\n结合几篇文章的内容，以及nvidia/opengl的Dockerfile来看，核心是安装libglvnd0及一些依赖库、配置好glvnd的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装mesa-utils和glmark2后，用glxinfo和glmark2都显示vendor是：\nOpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits) 即仍然在使用软渲染，但nvidia-smi在容器内工作又是正常的。\n使用集显 在Host机器上测试glxinfo和glmark2，发现vendor居然也不是nvidia而是MESA Intel，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。\n测试后，发现在docker run时附带--device=/dev/dri:/dev/dri参数即可。这样操作后，容器内glxinfo总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。\n关于Linux DRI，可参考Linux graphic subsystem(2)_DRI介绍的说明\n使用独显 话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明nvidia-smi工作正常，CUDA的代码也能运行。带此疑问，用why glxinfo not detect nvidia while nividia-smi works搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。\n最后本机上打开nvidia-settings查看设置时，发现Profile里的3个选项：\nNvidia (Performance mode) Nvidia On-Demand Intel (Power saving mode) 第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：\nNvidia On - Demand : Ubuntu\nthere’s a good write up here: https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html\non-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is ‘bumblebee mode’, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work. But you can’t turn the card off without ending your X session.\nThis new on-demand mode is pretty clunky but if you want nvidia on battery and don’t use external monitors and find logging out and in inconvenient, it’s good.\nAnd PSA: the gdm3 bug with optimus and modeset=1 is not fixed in 19.10, see https://bugs.launchpad.net/ubuntu/+source/gdm3/+bug/1716857\nswap to lightdm or run gdm3 as root to fix it.\n重点：\non-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen\n换句话说用外接显示器时On-Demand岂不是固定用了集显？切换Profile到Performance，重启，host上检查glxinfo，vendor果然变成了Nvidia。\n关于On-Demand，也可见graphics - How NVIDIA On-Demand option works in NVIDIA X Server Settings? - Ask Ubuntu的介绍\n另，有人明确不推荐On-Demand的使用：\nhttps://kfocus.org/wf/igpu.html\nWE DO NOT RECOMMEND USING NVIDIA ON-DEMAND mode (also called Hybrid Graphics Mode) in most circumstances; it keeps both the dGPU and iGPU running, can make multi-display systems run slowly, and can use significantly more power than Intel Mode alone even when idle. For these reason, we suggest using Intel Mode to conserve power and NVIDIA Performance Mode otherwise. One use-case that is an exception is when you are using the GPU for CUDA, OPTIX, or other compute purposes. In instance, switching to On-Demand can provide additional VRAM and GPU power for those jobs IF YOU NEED IT. Just remember to switch back when you are done.\nWhen using NVIDIA On-Demand, if you wish to launch an app using the NVIDIA GPU and Vulkan:\n# __NV_PRIME_RENDER_OFFLOAD=1 %appname% # Example: __NV_PRIME_RENDER_OFFLOAD=1 vkcube\nWhen using NVIDIA On-Demand, if you wish to launch an app using the NVIDIA GPU and OpenGL:\n# __NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia %appname% # Example sudo apt-get install mesa-utils # Get glxgears __NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia glxgears\n创建容器 在切换Profile后，创建运行容器，成功在容器内运行OpenGL程序，并通过x11转发在host中显示界面。Dockerfile如下：\nFROM ubuntu:18.04 ARG USER=docker ARG UID=1000 ARG GID=1000 # create a new user with same UID \u0026 PID but no password RUN groupadd --gid ${GID} ${USER} \u0026\u0026 \\ useradd --create-home ${USER} --uid=${UID} --gid=${GID} --groups root \u0026\u0026 \\ passwd --delete ${USER} # add user to the sudo group and set sudo group to no passoword RUN apt update \u0026\u0026 \\ apt install -y sudo \u0026\u0026 \\ adduser ${USER} sudo \u0026\u0026 \\ echo '%sudo ALL=(ALL) NOPASSWD:ALL' \u003e\u003e /etc/sudoers # configure OpenGL glvnd runtime for Nvidia # see https://hub.docker.com/r/nvidia/opengl for details RUN apt install -y --no-install-recommends libxau6 libxdmcp6 libxcb1 libxext6 libx11-6 # nvidia-container-runtime ENV NVIDIA_VISIBLE_DEVICES ${NVIDIA_VISIBLE_DEVICES:-all} ENV NVIDIA_DRIVER_CAPABILITIES ${NVIDIA_DRIVER_CAPABILITIES:+$NVIDIA_DRIVER_CAPABILITIES,}graphics,compat32,utility RUN echo \"/usr/local/nvidia/lib\" \u003e\u003e /etc/ld.so.conf.d/nvidia.conf \u0026\u0026 \\ echo \"/usr/local/nvidia/lib64\" \u003e\u003e /etc/ld.so.conf.d/nvidia.conf # Required for non-glvnd setups. ENV LD_LIBRARY_PATH /usr/lib/x86_64-linux-gnu:/usr/lib/i386-linux-gnu${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 RUN apt-get install -y --no-install-recommends libglvnd0 libgl1 libglx0 libegl1 libgles2 COPY 10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json # setup default user when enter the container USER ${UID}:${GID} WORKDIR /home/${USER} 创建镜像：\n#!/bin/bash set -e USER_ID=$(id -u) GROUP_ID=$(id -g) docker build --build-arg USER=\"$USER\" \\ --build-arg UID=\"$USER_ID\" \\ --build-arg GID=\"$GROUP_ID\" \\ --tag \"opengl-docker\" \\ --file ./Dockerfile \\ --progress=plain \\ . 运行容器：\n#!/bin/bash set -e # --restart always: always restart the container if it stops (except it is manually stopped by the user) # --network host: use the same network as the host, so the container is able to connect to the host xServer # --env TERM=xterm-256color: support color output in bash # --env DISPLAY=$DISPLAY: instructs X clients which X server to connect to # --runtime=nvidia: enable all GPU access inside the docker. nvidia-docker2 must be installed to use this option # --gpus all: expose all GPUs to the container. same as --runtime=nvidia # --volume=/tmp/.X11-unix/:/tmp/.X11-unix/: allow access to the host's X socket docker run -it \\ --name \"opengl-runtime\" \\ --restart always \\ --user \"${USER}\" \\ --workdir \"${PWD}\" \\ --network host \\ --env LANG=zh_CN.UTF-8 \\ --env TERM=xterm-256color \\ --env DISPLAY=\"${DISPLAY}\" \\ --env QT_X11_NO_MITSHM=1 \\ --runtime=nvidia \\ --volume=\"$HOME\":\"$HOME\" \\ --volume=/tmp/.X11-unix/:/tmp/.X11-unix/ \\ --detach \\ \"opengl-docker\" \\ /bin/bash 参考 Enabling GPUs in the Container Runtime Ecosystem | NVIDIA Technical Blog OpenGL and CUDA Applications in Docker | by Ben Botto | Medium docker中使用cuda、opengl、ros，支持rviz可视化_Vincent_PHY的博客-CSDN博客_docker cuda opengl docker - How do I pass data/info about the GPU (versions of OpenGL, OpenCL, mesa, etc…) from host to dockerimagr? - Stack Overflow ","wordCount":"756","inLanguage":"en","datePublished":"2023-01-01T10:01:29Z","dateModified":"2023-01-01T10:01:29Z","author":{"@type":"Person","name":"Qiao"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://tanjoe.github.io/posts/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93/"},"publisher":{"@type":"Organization","name":"Qiao","logo":{"@type":"ImageObject","url":"https://tanjoe.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tanjoe.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://tanjoe.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://tanjoe.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://tanjoe.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://tanjoe.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://tanjoe.github.io/posts/>Posts</a></div><h1 class=post-title>在容器内使用显卡进行渲染</h1><div class=post-meta><span title='2023-01-01 10:01:29 +0000 UTC'>2023-01-01</span>&nbsp;·&nbsp;Qiao</div></header><div class=post-content><p>由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词<em>nvidia opengl docker</em>搜索了一番，发现应该很好完成。</p><p>结合几篇文章的内容，以及<a href=https://hub.docker.com/r/nvidia/opengl>nvidia/opengl</a>的Dockerfile来看，核心是安装<code>libglvnd0</code>及一些依赖库、配置好<code>glvnd</code>的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装<code>mesa-utils</code>和<code>glmark2</code>后，用<code>glxinfo</code>和<code>glmark2</code>都显示vendor是：</p><pre tabindex=0><code>OpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits)
</code></pre><p>即仍然在使用软渲染，但<code>nvidia-smi</code>在容器内工作又是正常的。</p><h2 id=使用集显>使用集显<a hidden class=anchor aria-hidden=true href=#使用集显>#</a></h2><p>在Host机器上测试<code>glxinfo</code>和<code>glmark2</code>，发现vendor居然也不是nvidia而是<code>MESA Intel</code>，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。</p><p>测试后，发现在<code>docker run</code>时附带<code>--device=/dev/dri:/dev/dri</code>参数即可。这样操作后，容器内<code>glxinfo</code>总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。</p><blockquote><p>关于Linux DRI，可参考<a href=http://www.wowotech.net/graphic_subsystem/dri_overview.html>Linux graphic subsystem(2)_DRI介绍</a>的说明</p></blockquote><h2 id=使用独显>使用独显<a hidden class=anchor aria-hidden=true href=#使用独显>#</a></h2><p>话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明<code>nvidia-smi</code>工作正常，CUDA的代码也能运行。带此疑问，用<em>why glxinfo not detect nvidia while nividia-smi works</em>搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。</p><p>最后本机上打开<code>nvidia-settings</code>查看设置时，发现Profile里的3个选项：</p><ul><li>Nvidia (Performance mode)</li><li>Nvidia On-Demand</li><li>Intel (Power saving mode)</li></ul><p>第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：</p><blockquote><p><a href="https://www.reddit.com/r/Ubuntu/comments/deh01n/comment/f2v4iee/?utm_source=share&amp;utm_medium=web2x&amp;context=3">Nvidia On - Demand : Ubuntu</a></p><p>there&rsquo;s a good write up here: <a href=https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html>https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html</a></p><p>on-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is &lsquo;bumblebee mode&rsquo;, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work. But you can&rsquo;t turn the card off without ending your X session.</p><p>This new on-demand mode is pretty clunky but if you want nvidia on battery and don&rsquo;t use external monitors and find logging out and in inconvenient, it&rsquo;s good.</p><p>And PSA: the gdm3 bug with optimus and modeset=1 is not fixed in 19.10, see <a href=https://bugs.launchpad.net/ubuntu/+source/gdm3/+bug/1716857>https://bugs.launchpad.net/ubuntu/+source/gdm3/+bug/1716857</a></p><p>swap to lightdm or run gdm3 as root to fix it.</p></blockquote><p>重点：</p><p><strong>on-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen</strong></p><p>换句话说用外接显示器时On-Demand岂不是固定用了集显？切换Profile到Performance，重启，host上检查<code>glxinfo</code>，vendor果然变成了Nvidia。</p><blockquote><p>关于On-Demand，也可见<a href=https://askubuntu.com/a/1202902/1113947>graphics - How NVIDIA On-Demand option works in NVIDIA X Server Settings? - Ask Ubuntu</a>的介绍</p></blockquote><p>另，有人明确不推荐On-Demand的使用：</p><blockquote><p><a href=https://kfocus.org/wf/igpu.html>https://kfocus.org/wf/igpu.html</a></p><p><strong>WE DO NOT RECOMMEND USING <code>NVIDIA ON-DEMAND</code> mode (also called Hybrid Graphics Mode) in most circumstances</strong>; it keeps both the dGPU and iGPU running, can make multi-display systems run slowly, and can use significantly more power than Intel Mode alone even when idle. For these reason, we suggest using Intel Mode to conserve power and NVIDIA Performance Mode otherwise. One use-case that is an exception is when you are using the GPU for CUDA, OPTIX, or other compute purposes. In instance, switching to On-Demand can provide additional VRAM and GPU power for those jobs IF YOU NEED IT. Just remember to switch back when you are done.</p><p>When using <code>NVIDIA On-Demand</code>, if you wish to launch an app using the NVIDIA GPU and Vulkan:</p><p># __NV_PRIME_RENDER_OFFLOAD=1 %appname% # Example: __NV_PRIME_RENDER_OFFLOAD=1 vkcube</p><p>When using <code>NVIDIA On-Demand</code>, if you wish to launch an app using the NVIDIA GPU and OpenGL:</p><p># __NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia %appname% # Example sudo apt-get install mesa-utils # Get glxgears __NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia glxgears</p></blockquote><h2 id=创建容器>创建容器<a hidden class=anchor aria-hidden=true href=#创建容器>#</a></h2><p>在切换Profile后，创建运行容器，成功在容器内运行OpenGL程序，并通过x11转发在host中显示界面。Dockerfile如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-Dockerfile data-lang=Dockerfile><span class=line><span class=cl><span class=k>FROM</span><span class=s> ubuntu:18.04</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ARG</span> <span class=nv>USER</span><span class=o>=</span>docker
</span></span><span class=line><span class=cl><span class=k>ARG</span> <span class=nv>UID</span><span class=o>=</span><span class=m>1000</span>
</span></span><span class=line><span class=cl><span class=k>ARG</span> <span class=nv>GID</span><span class=o>=</span><span class=m>1000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># create a new user with same UID &amp; PID but no password</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> groupadd --gid <span class=si>${</span><span class=nv>GID</span><span class=si>}</span> <span class=si>${</span><span class=nv>USER</span><span class=si>}</span> <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    useradd --create-home <span class=si>${</span><span class=nv>USER</span><span class=si>}</span> --uid<span class=o>=</span><span class=si>${</span><span class=nv>UID</span><span class=si>}</span> --gid<span class=o>=</span><span class=si>${</span><span class=nv>GID</span><span class=si>}</span> --groups root <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    passwd --delete <span class=si>${</span><span class=nv>USER</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># add user to the sudo group and set sudo group to no passoword</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt update <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    apt install -y sudo <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    adduser <span class=si>${</span><span class=nv>USER</span><span class=si>}</span> sudo <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    <span class=nb>echo</span> <span class=s1>&#39;%sudo ALL=(ALL) NOPASSWD:ALL&#39;</span> &gt;&gt; /etc/sudoers<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># configure OpenGL glvnd runtime for Nvidia</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># see https://hub.docker.com/r/nvidia/opengl for details</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt install -y --no-install-recommends libxau6 libxdmcp6 libxcb1 libxext6 libx11-6<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># nvidia-container-runtime</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> NVIDIA_VISIBLE_DEVICES <span class=si>${</span><span class=nv>NVIDIA_VISIBLE_DEVICES</span><span class=k>:-</span><span class=nv>all</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> NVIDIA_DRIVER_CAPABILITIES <span class=si>${</span><span class=nv>NVIDIA_DRIVER_CAPABILITIES</span><span class=p>:+</span><span class=nv>$NVIDIA_DRIVER_CAPABILITIES</span><span class=p>,</span><span class=si>}</span>graphics,compat32,utility<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> <span class=nb>echo</span> <span class=s2>&#34;/usr/local/nvidia/lib&#34;</span> &gt;&gt; /etc/ld.so.conf.d/nvidia.conf <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    <span class=nb>echo</span> <span class=s2>&#34;/usr/local/nvidia/lib64&#34;</span> &gt;&gt; /etc/ld.so.conf.d/nvidia.conf<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Required for non-glvnd setups.</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> LD_LIBRARY_PATH /usr/lib/x86_64-linux-gnu:/usr/lib/i386-linux-gnu<span class=si>${</span><span class=nv>LD_LIBRARY_PATH</span><span class=p>:+:</span><span class=si>${</span><span class=nv>LD_LIBRARY_PATH</span><span class=si>}}</span>:/usr/local/nvidia/lib:/usr/local/nvidia/lib64<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt-get install -y --no-install-recommends libglvnd0 libgl1 libglx0 libegl1 libgles2<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> 10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># setup default user when enter the container</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>USER</span><span class=s> ${UID}:${GID}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>WORKDIR</span><span class=s> /home/${USER}</span><span class=err>
</span></span></span></code></pre></div><p>创建镜像：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nb>set</span> -e
</span></span><span class=line><span class=cl><span class=nv>USER_ID</span><span class=o>=</span><span class=k>$(</span>id -u<span class=k>)</span>
</span></span><span class=line><span class=cl><span class=nv>GROUP_ID</span><span class=o>=</span><span class=k>$(</span>id -g<span class=k>)</span>
</span></span><span class=line><span class=cl>docker build --build-arg <span class=nv>USER</span><span class=o>=</span><span class=s2>&#34;</span><span class=nv>$USER</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --build-arg <span class=nv>UID</span><span class=o>=</span><span class=s2>&#34;</span><span class=nv>$USER_ID</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --build-arg <span class=nv>GID</span><span class=o>=</span><span class=s2>&#34;</span><span class=nv>$GROUP_ID</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --tag <span class=s2>&#34;opengl-docker&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --file ./Dockerfile <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --progress<span class=o>=</span>plain <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    .
</span></span></code></pre></div><p>运行容器：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nb>set</span> -e
</span></span><span class=line><span class=cl><span class=c1># --restart always: always restart the container if it stops (except it is manually stopped by the user)</span>
</span></span><span class=line><span class=cl><span class=c1># --network host: use the same network as the host, so the container is able to connect to the host xServer</span>
</span></span><span class=line><span class=cl><span class=c1># --env TERM=xterm-256color: support color output in bash</span>
</span></span><span class=line><span class=cl><span class=c1># --env DISPLAY=$DISPLAY: instructs X clients which X server to connect to</span>
</span></span><span class=line><span class=cl><span class=c1># --runtime=nvidia: enable all GPU access inside the docker. nvidia-docker2 must be installed to use this option</span>
</span></span><span class=line><span class=cl><span class=c1># --gpus all: expose all GPUs to the container. same as --runtime=nvidia</span>
</span></span><span class=line><span class=cl><span class=c1># --volume=/tmp/.X11-unix/:/tmp/.X11-unix/: allow access to the host&#39;s X socket</span>
</span></span><span class=line><span class=cl>docker run -it <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --name <span class=s2>&#34;opengl-runtime&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --restart always <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --user <span class=s2>&#34;</span><span class=si>${</span><span class=nv>USER</span><span class=si>}</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --workdir <span class=s2>&#34;</span><span class=si>${</span><span class=nv>PWD</span><span class=si>}</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --network host <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --env <span class=nv>LANG</span><span class=o>=</span>zh_CN.UTF-8 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --env <span class=nv>TERM</span><span class=o>=</span>xterm-256color <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --env <span class=nv>DISPLAY</span><span class=o>=</span><span class=s2>&#34;</span><span class=si>${</span><span class=nv>DISPLAY</span><span class=si>}</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --env <span class=nv>QT_X11_NO_MITSHM</span><span class=o>=</span><span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --runtime<span class=o>=</span>nvidia <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --volume<span class=o>=</span><span class=s2>&#34;</span><span class=nv>$HOME</span><span class=s2>&#34;</span>:<span class=s2>&#34;</span><span class=nv>$HOME</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --volume<span class=o>=</span>/tmp/.X11-unix/:/tmp/.X11-unix/ <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --detach <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    <span class=s2>&#34;opengl-docker&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    /bin/bash
</span></span></code></pre></div><h2 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h2><ul><li><a href=https://developer.nvidia.com/blog/gpu-containers-runtime/>Enabling GPUs in the Container Runtime Ecosystem | NVIDIA Technical Blog</a></li><li><a href=https://medium.com/@benjamin.botto/opengl-and-cuda-applications-in-docker-af0eece000f1>OpenGL and CUDA Applications in Docker | by Ben Botto | Medium</a></li><li><a href=https://blog.csdn.net/sinat_37141443/article/details/115461863>docker中使用cuda、opengl、ros，支持rviz可视化_Vincent_PHY的博客-CSDN博客_docker cuda opengl</a></li><li><a href=https://stackoverflow.com/questions/45136499/how-do-i-pass-data-info-about-the-gpu-versions-of-opengl-opencl-mesa-etc>docker - How do I pass data/info about the GPU (versions of OpenGL, OpenCL, mesa, etc&mldr;) from host to dockerimagr? - Stack Overflow</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://tanjoe.github.io/tags/docker/>Docker</a></li><li><a href=https://tanjoe.github.io/tags/cuda/>CUDA</a></li><li><a href=https://tanjoe.github.io/tags/opengl/>OpenGL</a></li></ul><nav class=paginav><a class=prev href=https://tanjoe.github.io/posts/%E8%A7%A3%E5%86%B3%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cconda%E7%9A%84glibcxx%E9%97%AE%E9%A2%98/><span class=title>« Prev</span><br><span>解决容器内运行conda的GLIBCXX问题</span></a>
<a class=next href=https://tanjoe.github.io/posts/use-docker-with-nvidia-gpu-in-wsl2/><span class=title>Next »</span><br><span>Use docker with Nvidia GPU in WSL2</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://tanjoe.github.io/>Qiao</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>