<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Qiao</title>
    <link>https://tanjoe.github.io/posts/</link>
    <description>Recent content in Posts on Qiao</description>
    <image>
      <title>Qiao</title>
      <url>https://tanjoe.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://tanjoe.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 24 Mar 2023 14:46:42 +0000</lastBuildDate><atom:link href="https://tanjoe.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Debug Unity Project on Android Device</title>
      <link>https://tanjoe.github.io/posts/debug-unity-project-on-android-device/</link>
      <pubDate>Fri, 24 Mar 2023 14:46:42 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/debug-unity-project-on-android-device/</guid>
      <description>由于工作需要，在C++/Python的主业外，零零散散地与Unity打了些交道。这里记录下在安卓上调试Unity项目的要点。
修改Build Settings 点击File-&amp;gt;Build Settings，在Android build setting里勾选“Development Build”和“Script Debugging”。
开启USB调试 Android设备需开启USB调试选项。通常是在系统设置里查看系统信息，多次点击系统版本以启用开发者选项，再到开发者选项里启用USB调试即可。这一步是安卓开发的基础，略过不谈。
连接设备到PC 有线连接 有线连接即通过USB线将设备连接到PC即可。可以通过adb devices命令确定可用的设备。
无线连接 无线连接需要PC和Android设备连接到同一WIFI。
查看设备IP 可以在设备的系统设置里找到IP，通常是在网络的详情里。也可以用ADB查看，终端执行
adb shell ip addr show wlan0 连接到设备 PC终端执行
adb tcpip 5555 adb connect [AndroidDeviceIP]:5555 Attach Unity Debugger 在Android上运行Unity应用后，在Visual Studio中点击“Debug”-&amp;gt;“Attach Unity Debugger”：
随后选择对应的Android设备即可
设置Android SDK路径 如果系统中有多个Android SDK版本，在Select Unity Instance中可能不会看到对应的设备，这是因为Visual Studio使用的SDK工具没有对应。
在Unity中，点击Edit-&amp;gt;Preferences-&amp;gt;External Tools，复制所用的Android SDK工具路径：
随后在Visual Studio中，点击Tool-&amp;gt;Options-&amp;gt;Tools for Unity-&amp;gt;General，设置Preferred Android Sdk Root：
设置完成后，可能需要重新运行Unity应用，才能在Select Unity Instance中找到对应的设备。
Reference Debugging Unity Project On Android Device With Visual Studio – Siddharth Shanker Mishra Cannot Debug on Android Device from Visual Studio - Unity Forum </description>
    </item>
    
    <item>
      <title>Ubuntu 18.04上切换高版本GCC工具链</title>
      <link>https://tanjoe.github.io/posts/ubuntu-18.04%E4%B8%8A%E5%88%87%E6%8D%A2%E9%AB%98%E7%89%88%E6%9C%ACgcc%E5%B7%A5%E5%85%B7%E9%93%BE/</link>
      <pubDate>Sun, 19 Feb 2023 08:35:31 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/ubuntu-18.04%E4%B8%8A%E5%88%87%E6%8D%A2%E9%AB%98%E7%89%88%E6%9C%ACgcc%E5%B7%A5%E5%85%B7%E9%93%BE/</guid>
      <description>Ubuntu 18.04上切换高版本GCC工具链 添加软件源 $ sudo add-apt-repository ppa:ubuntu-toolchain-r/test 如果此前安装过非系统默认版本的python3，这一步有可能出错，产生类似
$ ModuleNotFoundError: No module named &amp;#39;apt_pkg&amp;#39; 的错误。解决方法是：
$ cd /usr/lib/python3/dist-packages $ sudo ln -s apt_pkg.cpython-36m-x86_64-linux-gnu.so apt_pkg.so 随后用update-alternatives将python3改回使用默认的版本：
$ sudo update-alternatives --config python3 # 选择默认的python3版本。在Ubuntu 18.04上，这个版本是 安装工具链 可以通过apt search gcc或在https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test?field.series_filter=bionic 上查看可用的gcc版本。这里选择安装gcc-11
$ sudo apt install gcc-11 g++-11 安装完成后，切换工具链
$ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 90 \ --slave /usr/bin/g++ g++ /usr/bin/g++-11 \ --slave /usr/bin/gcc-ar gcc-ar /usr/bin/gcc-ar-11 \ --slave /usr/bin/gcc-nm gcc-nm /usr/bin/gcc-nm-11 \ --slave /usr/bin/gcc-ranlib gcc-ranlib /usr/bin/gcc-ranlib-11 $ sudo upate-alternatives --config gcc # 选择gcc-11 检查版本：</description>
    </item>
    
    <item>
      <title>为VTK修复vtkOBJReader的一个segfault</title>
      <link>https://tanjoe.github.io/posts/%E4%B8%BAvtk%E4%BF%AE%E5%A4%8Dvtkobjreader%E7%9A%84%E4%B8%80%E4%B8%AAsegfault/</link>
      <pubDate>Wed, 18 Jan 2023 10:28:40 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E4%B8%BAvtk%E4%BF%AE%E5%A4%8Dvtkobjreader%E7%9A%84%E4%B8%80%E4%B8%AAsegfault/</guid>
      <description>Background 测试用PyTorch3D生成的Mesh时，打算用VTK对Mesh做离屏渲染生成图片，结果发现VTK的python binding和C++库都会在vtkOBJReader::Update时崩溃。由于是AI模型生成的OBJ文件，OBJ本身是有可能不太标准的，但用Blender、Open3D、trimesh测试，发现都可以加载该文件。看起来似乎VTK的vtkOBJReader实现不够健壮，遂决定调试一番。
Debug 以导致问题的OBJ文件编写复现demo，目录结构：
$ tree . . ├── assets │ ├── rand_0_diffuse.png │ ├── rand_0_normal.png │ ├── rand_0_skin.mtl │ ├── rand_0_skin.obj │ └── rand_0_spec.png ├── CMakeLists.txt └── main.cpp main.cpp：
#include &amp;lt;vtkOBJReader.h&amp;gt; int main() { vtkNew&amp;lt;vtkOBJReader&amp;gt; reader; reader-&amp;gt;SetFileName(&amp;#34;rand_0_skin.obj&amp;#34;); reader-&amp;gt;Update(); return 0; } 崩溃堆栈：
1 vtkAOSDataArrayTemplate&amp;lt;float&amp;gt;::GetTuple vtkAOSDataArrayTemplate.txx 275 0x7ffff6ee05e5 2 vtkOBJReader::RequestData vtkOBJReader.cxx 978 0x7ffff7b4c793 3 vtkPolyDataAlgorithm::ProcessRequest vtkPolyDataAlgorithm.cxx 87 0x7ffff28aaec6 4 vtkExecutive::CallAlgorithm vtkExecutive.cxx 734 0x7ffff287faf9 5 vtkDemandDrivenPipeline::ExecuteData vtkDemandDrivenPipeline.cxx 461 0x7ffff2876004 6 vtkCompositeDataPipeline::ExecuteData vtkCompositeDataPipeline.</description>
    </item>
    
    <item>
      <title>解决容器内运行conda的GLIBCXX问题</title>
      <link>https://tanjoe.github.io/posts/%E8%A7%A3%E5%86%B3%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cconda%E7%9A%84glibcxx%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 03 Jan 2023 17:54:29 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E8%A7%A3%E5%86%B3%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cconda%E7%9A%84glibcxx%E9%97%AE%E9%A2%98/</guid>
      <description>尝试在容器内运行conda，发现报错如下：
conda &amp;#34;ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.26&amp;#39; not found&amp;#34; 解决方式 安装libgcc
conda install libgcc 如果仍然报错，则
export LD_LIBRARY_PATH=&amp;lt;conda-env-path&amp;gt;/lib:$LD_LIBRARY_PATH conda-env-path替换为conda的目录，核心是通过修改LD_LIBRARY_PATH，让conda的python正确加载conda安装的libstdc++，而非系统的版本
To-Ask 为什么需要配环境变量？
按理来说conda在安装时应当已经修改了bashrc、zshrc等文件，让shell环境里的LD_LIBRARY_PATH带上了conda的lib目录（需要检查下未挂载home目录的容器以确认）。有可能是因为在启动容器时挂载了整个home目录，导致容器内的bash用了host的配置所致。
仔细想想，虽然挂载整个home目录用起来方便，但像shell配置、各类软件的cache本身是应该与host独立的，最好还是挂载home下的特定目录</description>
    </item>
    
    <item>
      <title>在容器内使用显卡进行渲染</title>
      <link>https://tanjoe.github.io/posts/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93/</link>
      <pubDate>Sun, 01 Jan 2023 10:01:29 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93/</guid>
      <description>由于要测试PyTorch3D生成的Mesh，而PyTorch3D的环境在本机又不好搭建，准备在Docker容器内做些渲染相关的工作，按关键词nvidia opengl docker搜索了一番，发现应该很好完成。
结合几篇文章的内容，以及nvidia/opengl的Dockerfile来看，核心是安装libglvnd0及一些依赖库、配置好glvnd的vendor json文件、设置nvidia docker的环境变量即可，但一番操作下来，在容器内安装mesa-utils和glmark2后，用glxinfo和glmark2都显示vendor是：
OpenGL renderer string: llvmpipe (LLVM 11.0.0, 256 bits) 即仍然在使用软渲染，但nvidia-smi在容器内工作又是正常的。
使用集显 在Host机器上测试glxinfo和glmark2，发现vendor居然也不是nvidia而是MESA Intel，也就是电脑的集成显卡。不过集成显卡就集成显卡吧，好歹让容器能够用集显，这样工作好歹可以继续。
测试后，发现在docker run时附带--device=/dev/dri:/dev/dri参数即可。这样操作后，容器内glxinfo总算显示vendor是集成显卡了，由于工作要求的渲染性能不高，代码倒也能跑起来。
关于Linux DRI，可参考Linux graphic subsystem(2)_DRI介绍的说明
使用独显 话说回来，为什么host和容器都显示vendor是集显而非Nvidia的独显？明明nvidia-smi工作正常，CUDA的代码也能运行。带此疑问，用why glxinfo not detect nvidia while nividia-smi works搜索一番，发现Nvidia的论坛里也有些相似的问题，但求助都没有明确答复。
最后本机上打开nvidia-settings查看设置时，发现Profile里的3个选项：
Nvidia (Performance mode) Nvidia On-Demand Intel (Power saving mode) 第3个很好理解，但Nvidia Performance mode和On-Demand又有什么区别？搜索一番，发现此贴：
Nvidia On - Demand : Ubuntu
there&amp;rsquo;s a good write up here: https://www.linuxuprising.com/2019/08/nvidia-43517-linux-beta-driver-adds.html
on-demand means the Ubuntu optimus tool now lets you have dynamic switching of nvidia, but output is limited to the laptop screen, which is &amp;lsquo;bumblebee mode&amp;rsquo;, or the normal ubuntu Nvidia mode, which turns on the card after you restart X; this mode uses nvidia to render everything, and external monitors work.</description>
    </item>
    
    <item>
      <title>Use docker with Nvidia GPU in WSL2</title>
      <link>https://tanjoe.github.io/posts/use-docker-with-nvidia-gpu-in-wsl2/</link>
      <pubDate>Tue, 13 Dec 2022 20:13:00 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/use-docker-with-nvidia-gpu-in-wsl2/</guid>
      <description>GPU Support 先确认Docker Desktop的Backend使用的是WSL2，并且Windows、Nvidia驱动的版本足够，随后管理员权限终端执行wsl --update更新wsl。完成后，终端执行
docker run --rm -it --gpus=all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark 如果GPU可用，则输出类似于
Run &amp;#34;nbody -benchmark [-numbodies=&amp;lt;numBodies&amp;gt;]&amp;#34; to measure performance. -fullscreen (run n-body simulation in fullscreen mode) -fp64 (use double precision floating point values for simulation) -hostmem (stores simulation data in host memory) -benchmark (run benchmark to measure performance) -numbodies=&amp;lt;N&amp;gt; (number of bodies (&amp;gt;= 1) to run in simulation) -device=&amp;lt;d&amp;gt; (where d=0,1,2.... for the CUDA device to use) -numdevices=&amp;lt;i&amp;gt; (where i=(number of CUDA devices &amp;gt; 0) to use for simulation) -compare (compares simulation results running once on the default GPU and once on the CPU) -cpu (run n-body simulation on the CPU) -tipsy=&amp;lt;file.</description>
    </item>
    
    <item>
      <title>使用Github Actions部署Hexo</title>
      <link>https://tanjoe.github.io/posts/%E4%BD%BF%E7%94%A8github-actions%E9%83%A8%E7%BD%B2hexo/</link>
      <pubDate>Sat, 10 Dec 2022 16:28:00 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E4%BD%BF%E7%94%A8github-actions%E9%83%A8%E7%BD%B2hexo/</guid>
      <description>切换到Hexo写博客后，每次换电脑都要来遍NodeJS、Hexo的配置。虽然不算困难，但挺消耗写文章的心情，故决定折腾下Github CI，实现写完文章后推送就自动完成Hexo的生成和部署，这样方便专注于文章的撰写，不被环境搭建分散精力。
设置仓库 准备两个仓库，一个为博客源码仓库，一个是静态页面仓库。
博客源码仓库：名称任意，设为私有
静态页面仓库：名称需按照xxx.github.io格式来，必须设为公开的，存放Hexo生成的内容。参考https://pages.github.com/
设置密钥 为了向静态页面仓库推送内容，需要添加一对SSH密钥，其中公钥设置到静态页面仓库，私钥设置到源码仓库。
生成密钥
ssh-keygen -t ed25519 -C &amp;#34;your_email@example.com&amp;#34; 在Github的静态仓库页面，添加新的Deploy Key。在Settings -&amp;gt; Deploy keys -&amp;gt; Add new中，填入任意Title，Value则是新生成的公钥内容。由于要往此仓库推送，需勾选”Allow Write Access“。
在Github的源码仓库页面，在Settings -&amp;gt; Secrets -&amp;gt; Actions中点击New repository secret，Name设置为DEPLOY_KEY（后面配置Github Actions的脚本时会用NAME索引到此secret），Value填入新生成私钥的内容
定义Workflows 在源码仓库根目录下，创建.github/workflows/hexo_deploy.yml文件，内容如下：
name: HEXO_DEPLOY on: push: branches: - master jobs: build: runs-on: ubuntu-latest steps: - name: Checkout source uses: actions/checkout@v2.5.0 with: ref: master submodules: &amp;#39;true&amp;#39; - name: Use Node.js uses: actions/setup-node@v3 with: node-version: 18 - name: Setup hexo env: ACTION_DEPLOY_KEY: ${{ secrets.</description>
    </item>
    
    <item>
      <title>利用strace查找文件热点</title>
      <link>https://tanjoe.github.io/posts/%E5%88%A9%E7%94%A8strace%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E7%83%AD%E7%82%B9/</link>
      <pubDate>Fri, 25 Feb 2022 18:04:35 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E5%88%A9%E7%94%A8strace%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E7%83%AD%E7%82%B9/</guid>
      <description>在做性能调优时，遇到这么一个问题：已知国产机（飞腾+麒麟OS）上机械硬盘的性能非常差，文件读写会有不少开销，那么怎么跟踪程序的读写情况，尽量优化掉不必要的读写呢？这需要查找文件热点。对于这项工作，BPF Compiler Collection里的filetop是个很好的选择，不过BCC这组工具在麒麟OS源里没有提供，遂考虑用strace实现。
跟踪系统调用 严格来说，strace并不能直接跟踪文件的读写情况，而是跟踪所有接受一个文件名为参数的系统调用。不过无论是频繁读写还是频繁判断文件状态，对于调优而言都是可待优化的，因此这里没有严格区分两者。
跟踪文件相关的系统调用：
$ strace -t -e trace=file -o strace.log COMMAND # --trace=file # Trace all system calls which take a file name as an argument. You can think of this as an abbreviation for -e trace=open,stat,chmod,unlink,... which is useful to seeing what files the process is referencing. --trace=还可以使用process、network、signal、desc、memory等等，参见https://man7.org/linux/man-pages/man1/strace.1.html
示例
$ strace -t -e trace=file -o strace.log fc-list $ cat strace.log 18:07:24 execve(&amp;#34;/home/tanqiao/program/hotspot/hotspot&amp;#34;, [&amp;#34;hotspot&amp;#34;], 0x7ffc0b28a138 /* 80 vars */) = 0 18:07:24 access(&amp;#34;/etc/ld.</description>
    </item>
    
    <item>
      <title>Add dynamic tracing point in C&#43;&#43; dynamic library</title>
      <link>https://tanjoe.github.io/posts/add-dynamic-tracing-point-in-c&#43;&#43;-dynamic-library/</link>
      <pubDate>Fri, 25 Feb 2022 17:28:59 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/add-dynamic-tracing-point-in-c&#43;&#43;-dynamic-library/</guid>
      <description>List functions To list all functions exported
$ perf probe -x libQt5CoreKso.so --funcs --filter &amp;#39;*&amp;#39; If you don&amp;rsquo;t add --filter &#39;*&#39;, then all functions that start with _ will be filtered by default
To list all functions in original form:
$ perf probe -x libQt5CoreKso.so --funcs --no-demangle --filter &amp;#39;*&amp;#39; Combine with grep, you can find the desired function
$ perf probe -x libQt5CoreKso.so --funcs --no-demangle --filter &amp;#39;*&amp;#39; | grep setValue _ZN6kso_qt11QJsonObject10setValueAtEiRKNS_10QJsonValueE _ZN6kso_qt18QCommandLineOption12setValueNameERKNS_7QStringE _ZN6kso_qt24QVariantAnimationPrivate10setValueAtEdRKNS_8QVariantE _ZN6kso_qt9QSettings8setValueERKNS_7QStringERKNS_8QVariantE Add tracing point To add a function as tracing point:</description>
    </item>
    
    <item>
      <title>用Rclone在Linux下与OneDrive同步</title>
      <link>https://tanjoe.github.io/posts/%E7%94%A8rclone%E5%9C%A8linux%E4%B8%8B%E4%B8%8Eonedrive%E5%90%8C%E6%AD%A5/</link>
      <pubDate>Fri, 25 Feb 2022 15:19:51 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E7%94%A8rclone%E5%9C%A8linux%E4%B8%8B%E4%B8%8Eonedrive%E5%90%8C%E6%AD%A5/</guid>
      <description>接触Obsidian以后，决心将笔记从OneNote转换成Markdown格式，再由Obisian管理，同步则还是用OneDrive。OneDrive在Linux下没有客户端，不过可以借助Rclone与OneDrive API交互做同步。
安装 curl https://rclone.org/install.sh | sudo bash 配置 Rclone的文档相当齐全，这里参考https://rclone.org/onedrive/ 进行配置。终端输入
rclone config 按提示设定storage的名称（这里设定为onedrive），选择storage类型为Microsoft OneDrive，随后Rclone会唤起浏览器打开登录页面
e) Edit existing remote n) New remote d) Delete remote r) Rename remote c) Copy remote s) Set configuration password q) Quit config e/n/d/r/c/s/q&amp;gt; n name&amp;gt; onedrive Type of storage to configure. Enter a string value. Press Enter for the default (&amp;#34;&amp;#34;). Choose a number from below, or type in your own value [snip] XX / Microsoft OneDrive \ &amp;#34;onedrive&amp;#34; [snip] Storage&amp;gt; onedrive Microsoft App Client Id Leave blank normally.</description>
    </item>
    
    <item>
      <title>poor-man-s-profiler</title>
      <link>https://tanjoe.github.io/posts/poor-man-s-profiler/</link>
      <pubDate>Fri, 11 Feb 2022 16:12:59 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/poor-man-s-profiler/</guid>
      <description>背景 Linux下perf可以说是首选的性能调优工具——无需重新编译目标软件，支持采样多种类型的事件，开销相对较小。不过perf也有明显的缺点，perf是通过采样事件（并且通常都是采样CPU事件）来记录软件运行情况的，因此它的结果往往只能反映程序在某一方面的表现。
换而言之，如果perf采样的是CPU事件，那么其结果只能代表程序On-CPU的表现，至于Off-CPU部分则需要另外采样。虽然也可以通过采样sched:sched_stat_sleep、sched:sched_switch、sched:sched_process_exit来间接分析Off-CPU的情况，但Off-CPU瓶颈的类型可能有很多（IO、线程同步、内存等），只采样特定事件分析容易有所遗漏。
这自然地引出一个问题：有没有工具能够按固定时间间隔记录程序当前调用栈？
不幸的是，perf虽然支持记录cpu-clock、task-clock事件，但内核并没有提供类似于wall-clock的事件。其它采样工具，诸如gprof、gperftools、Valgrind也是如此。
poor man&amp;rsquo;s profiler 所谓的poor man&amp;rsquo;s profiler，其原理非常简单。用GDB启动（或关联到）进程，并按一定间隔中断进程并检查当前调用栈，函数的开销则与其在调用栈中出现的频率成正比。
一个简单的实现，poor-profiler.sh：
#!/bin/bash set -e command=&amp;#34;&amp;#34; sample_number=100 sleep_time=0.01 output_file=&amp;#34;poorman-profiler.log&amp;#34; PID=0 # parse arguments while getopts e:n:t:o:p: flag do case &amp;#34;${flag}&amp;#34; in e) command=${OPTARG} ;; n) sample_number=${OPTARG} ;; t) sleep_time=${OPTARG} ;; o) output_file=${OPTARG} ;; p) PID=${OPTARG} ;; *) echo &amp;#34;${OPTARG} are ignored&amp;#34; &amp;gt;&amp;amp;2 ;; esac done # remove old log if [ -f &amp;#34;$output_file&amp;#34; ] ; then rm -v &amp;#34;$output_file&amp;#34; fi # run command in background if not empty if [ -n &amp;#34;$VAR&amp;#34; ]; then ${command} &amp;amp; PID=$!</description>
    </item>
    
    <item>
      <title>处理托管C&#43;&#43;的EEFileLoadException</title>
      <link>https://tanjoe.github.io/posts/%E5%A4%84%E7%90%86%E6%89%98%E7%AE%A1c&#43;&#43;%E7%9A%84eefileloadexception/</link>
      <pubDate>Wed, 04 Nov 2020 11:58:00 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E5%A4%84%E7%90%86%E6%89%98%E7%AE%A1c&#43;&#43;%E7%9A%84eefileloadexception/</guid>
      <description>背景 因为业务的原因，需要从C++端调用一个C#库，设计的调用流程如下：
graph LR; n[&amp;#34;Native C++&amp;#34;]--&amp;gt;m[&amp;#34;Managed C++&amp;#34;]; m--&amp;gt;s[&amp;#34;C#&amp;#34;]; 工程的组织如下：
graph LR; subgraph &amp;#34;Native C++&amp;#34; user[&amp;#34;Native C++库使用者&amp;#34;] nt[&amp;#34;Native C++库单元测试&amp;#34;]; n[&amp;#34;Native C++库&amp;#34;]; end m[&amp;#34;Managed C++库&amp;#34;]; subgraph &amp;#34;C#&amp;#34; s[&amp;#34;C#库&amp;#34;]; st[&amp;#34;C#库单元测试&amp;#34;]; end user-.-&amp;gt;|显式加载|n; nt--&amp;gt;n; n--&amp;gt;m; m--&amp;gt;s; st--&amp;gt;s; 动态库工程：
Native C++库：生成Unmanaged.lib和Unmanaged.dll Managed C++库：生成Wrapper.lib和Wrapper.dll C#库：生成Managed.dll 可执行文件工程：
Native C++库单元测试：生成UnmanagedTest.exe C#库单元测试：生成ManagedTest.exe Native C++库使用者：生成LibConsumer.exe。与单元测试工程不同的是，LibConsumer.exe会在运行期间调用::LoadLibrary()显示加载Unmanaged.dll，在链接期也不会链接到Unmanaged.lib和Wrapper.lib 现在情况如下：C#库编写完成，且C#库单元测试通过，但Native C++库单元测试未通过，LibConsumer.exe加载Unmanaged.dll也会失败（::LoadLibrary()返回句柄为NULL）。调试发现在托管C++层创建C#对象时会出现EEFileLoadException导致程序崩溃。
EEFileLoadException Microsoft Docs没有找到对EEFileLoadException的描述，不过Stackoverflow上有个简要的回答，见EEFileLoadException When Loading C++ DLL in Managed DLL：
An EEFileLoadException indicates the executable cannot find or load one of it&amp;rsquo;s dependencies. That can of course has different causes (path problem, mixing configurations, mixing platforms).</description>
    </item>
    
    <item>
      <title>在Windows环境下编译Qt-5-15-1</title>
      <link>https://tanjoe.github.io/posts/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%BC%96%E8%AF%91qt-5-15-1/</link>
      <pubDate>Mon, 21 Sep 2020 15:11:34 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%BC%96%E8%AF%91qt-5-15-1/</guid>
      <description>自Qt 5.15开始，Qt对于开源用户只提供源码包的下载，不再提供预编译安装包。这一策略或是为了促使更多人购买Qt的商用授权。无论对这一决策的态度如何，自Qt 5.15开始，无论是使用静态库还是动态库，编译Qt都将是一个必不可少的步骤了。
1 源码下载 Qt 5.15.1的下载地址：Qt 5.15.x source packages
也可以从国内的镜像下载，Qt的镜像列表：https://download.qt.io/static/mirrorlist/
下载qt-everywhere-src-5.15.1.zip后解压，这里假定将源码解压到qt5.15.1-src目录。
2 编译环境搭建 在Windows环境下从源码编译安装Qt，除VS开发环境外，还需要先安装Perl和Python。此外，还有一些可选的三方库可以安装，如OpenSSL Toolkit、ICU、ANGLE，这些库可以为Qt提供额外的特性，但并不是必要的，参见Qt官方文档对编译环境的描述：Qt for Windows - Requirements Qt 5.14。
2.1 Visual Studio Qt可以使用VS 2015，VS 2017，VS 2019进行构建。这里选择使用VS 2019，从https://visualstudio.microsoft.com/zh-hans/ 下载安装即可。
2.2 Perl Perl的Windows版本有2种可以下载，分别是ActivePerl和StrawberryPerl。其中ActivePerl需要注册后下载，StrawberryPerl可以直接下载，推荐StrawberryPerl。
StrawberryPerl下载地址：Strawberry Perl for Windows
安装时默认会添加perl到环境变量。安装完成后，可以通过命令行执行perl -v测试环境变量是否安装成功。
2.3 Python 对于Python，Python 2只被qpdf、qwebengine等几个模块需要，如果不需要这几个模块可以只安装Python 3。这里选择只安装Python 3。
在Windows 10下安装Python的注意事项
从Windows 10 2019 五月更新以来，微软试图把 Python 带到 Windows，因此在C:\Users\%USERNAME%\AppData\Local\Microsoft\WindowsApps路径下加入了python.exe、python3.exe几个占位文件。
这几个文件并非真正的python解释器，执行后会弹出Windows Store页面并定位到Python App的详情页。由于这几个文件也处在系统的PATH环境变量内，当用户执行python时有可能会调用占位文件而非实际的python解释器，从而导致运行错误。
可以通过以下步骤关闭该设置：
输入app exec打开Windows的“应用程序别名”界面
关闭为python.exe和python2.exe设置的别名
下载Python：Python Releases for Windows Python.org
安装时选择将Python加入环境变量。可以在命令行内输入python，检查Python解释器是否会运行。
2.4 LLVM 从Qt 5.</description>
    </item>
    
    <item>
      <title>在Windows上编译VTK-9-0-1及其示例</title>
      <link>https://tanjoe.github.io/posts/%E5%9C%A8windows%E4%B8%8A%E7%BC%96%E8%AF%91vtk-9-0-1%E5%8F%8A%E5%85%B6%E7%A4%BA%E4%BE%8B/</link>
      <pubDate>Thu, 17 Sep 2020 11:42:52 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E5%9C%A8windows%E4%B8%8A%E7%BC%96%E8%AF%91vtk-9-0-1%E5%8F%8A%E5%85%B6%E7%A4%BA%E4%BE%8B/</guid>
      <description>1 准备工作 在Windows下编译VTK需要以下内容：
CMake 3.10及以上 Visual Studio及MSVC编译环境 VTK源码 1.1 下载VTK源码 可以在https://vtk.org/download/ 下载VTK的源码、测试数据、文档等内容
其中，VTKData-9.0.1.tar.gz是VTK用于测试的数据，VTKLargeData-9.0.1.tar.gz是VTK部分示例程序所用的数据，这两个文件都可以不用下载，只下载VTK-9.0.1.tar.gz即可。
2 生成VTK 2.1 创建目录 为VTK创建一个文件夹 在文件夹内，创建src和build目录，分别存放源码和生成的文件 将VTK-9.0.1.tar.gz解压到src内 目录结构类似于：
c:\data\cpp\vtk\build &amp;lt;--空 c:\data\cpp\vtk\src c:\data\cpp\vtk\src\Accelerators c:\data\cpp\vtk\src\Charts c:\data\cpp\vtk\src\.... 2.2 运行CMake 打开CMake-GUI
选择VTK的源码路径和生成路径
点击“Configure”
选择需要的“generator”，这里选择Visual Studio 15 2017 Win64作为生成器
根据需要调整CMake选项。以下为部分常见的选项：
CMAKE_INSTALL_PRFIX：生成的VTK库的安装路径。根据需要选择即可
VTK_BUILD_EXAMPLES：默认为OFF，勾选后生成测试时将一并生成示例代码。由于源码中的测试工程管理不便，且测试资源需要单独下载和配置，这里选择不生成源码中的示例，后续单独克隆VTK的测试代码仓库并生成。
VTK_USE_CUDA：默认为OFF，勾选后开启对CUDA的支持
VTK_GROUP_QT：勾选后将开启对Qt的支持，编译VTK在Qt中的控件类等
再次点击“Configure”进行配置
点击“Generator”生成VS 2017对应的工程
点击&amp;quot;Open Project&amp;quot;，这时会调用VS 2017打开CMake生成的工程
2.3 构建 在VS 2017中将配置切换到&amp;quot;Release&amp;quot;，右键ALL_BUILD项目，选择“生成”即可。构建完成后，在build/bin/Release下便能看到编译好的动态库文件。
2.4 安装 右键INSTALL项目，选择“生成”即可将VTK相关的头文件、库文件、动态库文件安装到CMAKE_INSTALL_PREFIX指定的位置。安装完成后，目录结构应类似于：
c:\program file\VTK\bin c:\program file\VTK\include c:\program file\VTK\lib c:\program file\VTK\share 其中，\bin目录包含了所有的VTK动态库文件，可以该路径加入环境变量。
如果需要更改安装路径，再次打开CMake-GUI更改CMAKE_INSTALL_PREFIX后，重新加载工程生成INSTALL即可
3 生成示例 3.1 示例的来源 如前所言，VTK源码包内已经附带了一些示例程序，这些示例程序旨在以简单一致的格式来说明VTK的一些概念，然而这些例子只涵盖了VTK功能的一小部分。</description>
    </item>
    
    <item>
      <title>如何使用git submodule和git filter-repo从仓库中分离特定目录</title>
      <link>https://tanjoe.github.io/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8git-submodule%E5%92%8Cgit-filter-repo%E4%BB%8E%E4%BB%93%E5%BA%93%E4%B8%AD%E5%88%86%E7%A6%BB%E7%89%B9%E5%AE%9A%E7%9B%AE%E5%BD%95/</link>
      <pubDate>Thu, 23 Jul 2020 10:09:23 +0000</pubDate>
      
      <guid>https://tanjoe.github.io/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8git-submodule%E5%92%8Cgit-filter-repo%E4%BB%8E%E4%BB%93%E5%BA%93%E4%B8%AD%E5%88%86%E7%A6%BB%E7%89%B9%E5%AE%9A%E7%9B%AE%E5%BD%95/</guid>
      <description>碰到了一个这样的场景：同事为了单元测试，将众多测试资源文件提交到了git仓库内，这导致仓库体积陡然膨胀。但另一方面，编写好的测试用例又确实依赖这些测试资源文件。那么，有没有办法能达到以下目标：
分离工程文件和测试资源，以便能够单独管理二者 清洗提交记录，将测试资源在提交历史中“抹去”，以便减小仓库的体积 搜索一番，发现了git submodule和git filter-repo两个工具刚好可以满足这两个需求。
1 git submodule的使用 submodule是git自带的一个工具，详细的介绍参见Git-工具-子模块，这里不再赘述，只简单说明如何利用git submodule满足上述需求。
1.1 从仓库中移除测试资源 假设工程结构如下：
├─MyLib │ ├─include │ └─src ├─MyLibTest ├─assets └─src 其中MyLib为库的工程，而MyLibTest则是MyLib的单元测试工程，测试资源存放在MyLibTest/assets下，也正是我们需要移除的目录。
首先，在git bash中执行
git rm -r --cached MyLibTest/assets 将MyLibTest/assets从git仓库索引中移除，但不实际删除该目录。
关于git rm的使用，参见git-rm
1.2 新建测试资源仓库 新建远程仓库 在git服务器上新建一个仓库，记作MyLibTestResource，用于存放测试资源。
新建本地仓库 新建一个目录，这里记作TestResource，在其中建立git仓库，将MyLibTest/assets中的内容复制到该目录下，随后提交。再执行
git remote add origin git@MyLibTestResource.git #git@MyLibTestResource.git替换为MyLibTestResource的真实git地址 添加远程仓库，随后执行git push推送即可。
1.3 添加子模块 回到MyLib下，执行
git submodule add git@MyLibTestResource.git MyLibTest/assets 添加子模块MyLibTestResource，子模块的内容会同步到MyLibTest/assets下。
1.4 克隆包含子模块的项目 克隆包含子模块的项目有二种方法：一种是先克隆父项目，再更新子模块；另一种是直接递归克隆整个项目。
克隆父项目，再更新子模块 #克隆父项目MyLib git clone git@MyLib.git #git@MyLib.git替换为MyLib的真实git地址 #初始化子模块 cd MyLib git submodule init #更新子模块 git submodule update 递归克隆整个项目 git clone git@MyLib.</description>
    </item>
    
  </channel>
</rss>
